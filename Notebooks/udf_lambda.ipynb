{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, LongType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Learning_Spark_UDF_LAMBDA\") \\\n",
    "    .config('spark.ui.port', '4050')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e03050",
   "metadata": {},
   "source": [
    "## Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9bd8a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_squared_typed_long(number)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_squared_typed_long(number):\n",
    "    return number * number\n",
    "spark.udf.register(\"squaredWithPython\", make_squared_typed_long, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9188e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|id |\n",
      "+---+\n",
      "|1  |\n",
      "|2  |\n",
      "|3  |\n",
      "|4  |\n",
      "|5  |\n",
      "|6  |\n",
      "|7  |\n",
      "|8  |\n",
      "|9  |\n",
      "|10 |\n",
      "|11 |\n",
      "|12 |\n",
      "|13 |\n",
      "|14 |\n",
      "|15 |\n",
      "|16 |\n",
      "|17 |\n",
      "|18 |\n",
      "|19 |\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1, 20).createOrReplaceTempView(\"numbers_temp_table\")\n",
    "numbers_dataframe = spark.table(\"numbers_temp_table\")\n",
    "numbers_dataframe.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229d0bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|id |id_squared|\n",
      "+---+----------+\n",
      "|1  |1         |\n",
      "|2  |4         |\n",
      "|3  |9         |\n",
      "|4  |16        |\n",
      "|5  |25        |\n",
      "|6  |36        |\n",
      "|7  |49        |\n",
      "|8  |64        |\n",
      "|9  |81        |\n",
      "|10 |100       |\n",
      "|11 |121       |\n",
      "|12 |144       |\n",
      "|13 |169       |\n",
      "|14 |196       |\n",
      "|15 |225       |\n",
      "|16 |256       |\n",
      "|17 |289       |\n",
      "|18 |324       |\n",
      "|19 |361       |\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf(\"long\")\n",
    "def make_squared_typed_long(number):\n",
    "    return number * number\n",
    "numbers_dataframe = spark.table(\"numbers_temp_table\")\n",
    "numbers_dataframe.select(\"id\", make_squared_typed_long(\"id\").alias(\"id_squared\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878e674",
   "metadata": {},
   "source": [
    "## Python Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ebfea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 100, 400, 2916, 81]\n"
     ]
    }
   ],
   "source": [
    "lista_numeros = [2, 10, 20, 54, 9]\n",
    "numero_quadrado = map(lambda numero: numero ** 2, lista_numeros)\n",
    "print(list(numero_quadrado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9811d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_quadrado(lista_numeros):\n",
    "    nova_lista = []\n",
    "    for i in lista_numeros:\n",
    "        quadrado = i ** 2\n",
    "        nova_lista.append(quadrado)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236e81a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 100, 400, 2916, 81]\n"
     ]
    }
   ],
   "source": [
    "numero_quadrado_2 = numero_quadrado(lista_numeros)\n",
    "print(numero_quadrado_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b23eba",
   "metadata": {},
   "source": [
    "# Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee72176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"sales\", FloatType(),True),    \n",
    "    StructField(\"employee\", StringType(),True),\n",
    "    StructField(\"ID\", IntegerType(),True)\n",
    "])\n",
    "\n",
    "sales_data = [[ 10.2, \"Fred\",123], [50.35, \"Barney\", 200]]\n",
    "\n",
    "sales_dataframe = spark.createDataFrame(sales_data,schema=schema)\n",
    "\n",
    "cols_to_int = udf(lambda z: to_int(z), IntegerType())\n",
    "spark.udf.register(\"cols_to_int\", cols_to_int)\n",
    "\n",
    "def to_int(number):\n",
    "    \n",
    "    if isinstance(number, str) == True:\n",
    "        converted = [str(ord(i)) for i in number]\n",
    "        return(int(''.join(converted)))\n",
    "    else:\n",
    "         return Null\n",
    "\n",
    "\n",
    "sales_dataframe_2 = sales_dataframe.withColumn( 'employee_converted',cols_to_int('employee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aec987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---+------------------+\n",
      "|sales|employee| ID|employee_converted|\n",
      "+-----+--------+---+------------------+\n",
      "| 10.2|    Fred|123|        1394624364|\n",
      "|50.35|  Barney|200|        1670219393|\n",
      "+-----+--------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_dataframe_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3248d4d",
   "metadata": {},
   "source": [
    "Obs.: The ord() function in Python accepts a string of length 1 as an argument and returns the unicode code point representation of the passed argument. For example ord('B') returns 66 which is a unicode code point value of character 'B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b876331",
   "metadata": {},
   "source": [
    "# ReferÃªncias\n",
    "\n",
    "1. https://docs.databricks.com/spark/latest/spark-sql/udf-python.html\n",
    "2. https://www.bmc.com/blogs/how-to-write-spark-udf-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7913c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
